{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "base_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>mu</th>\n",
       "      <th>alpha</th>\n",
       "      <th>homo</th>\n",
       "      <th>lumo</th>\n",
       "      <th>gap</th>\n",
       "      <th>r2</th>\n",
       "      <th>zpve</th>\n",
       "      <th>U0</th>\n",
       "      <th>U</th>\n",
       "      <th>H</th>\n",
       "      <th>G</th>\n",
       "      <th>CV</th>\n",
       "      <th>Structure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157.71180</td>\n",
       "      <td>157.709970</td>\n",
       "      <td>157.706990</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13.21</td>\n",
       "      <td>-0.3877</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.5048</td>\n",
       "      <td>35.3641</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>-40.478930</td>\n",
       "      <td>-40.476062</td>\n",
       "      <td>-40.475117</td>\n",
       "      <td>-40.498597</td>\n",
       "      <td>6.469</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>799.58812</td>\n",
       "      <td>437.903860</td>\n",
       "      <td>282.945450</td>\n",
       "      <td>1.8511</td>\n",
       "      <td>6.31</td>\n",
       "      <td>-0.2928</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.3615</td>\n",
       "      <td>19.0002</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>-76.404702</td>\n",
       "      <td>-76.401867</td>\n",
       "      <td>-76.400922</td>\n",
       "      <td>-76.422349</td>\n",
       "      <td>6.002</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>35.610036</td>\n",
       "      <td>35.610036</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>16.28</td>\n",
       "      <td>-0.2845</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>59.5248</td>\n",
       "      <td>0.026841</td>\n",
       "      <td>-77.308427</td>\n",
       "      <td>-77.305527</td>\n",
       "      <td>-77.304583</td>\n",
       "      <td>-77.327429</td>\n",
       "      <td>8.574</td>\n",
       "      <td>C#C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285.48839</td>\n",
       "      <td>38.982300</td>\n",
       "      <td>34.298920</td>\n",
       "      <td>2.1089</td>\n",
       "      <td>14.18</td>\n",
       "      <td>-0.2670</td>\n",
       "      <td>-0.0406</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>59.9891</td>\n",
       "      <td>0.026603</td>\n",
       "      <td>-114.483613</td>\n",
       "      <td>-114.480746</td>\n",
       "      <td>-114.479802</td>\n",
       "      <td>-114.505268</td>\n",
       "      <td>6.413</td>\n",
       "      <td>C=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.46225</td>\n",
       "      <td>19.906490</td>\n",
       "      <td>19.906330</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>23.95</td>\n",
       "      <td>-0.3385</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>109.5031</td>\n",
       "      <td>0.074542</td>\n",
       "      <td>-79.764152</td>\n",
       "      <td>-79.760666</td>\n",
       "      <td>-79.759722</td>\n",
       "      <td>-79.787269</td>\n",
       "      <td>10.098</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           A           B           C      mu  alpha    homo    lumo     gap  \\\n",
       "0  157.71180  157.709970  157.706990  0.0000  13.21 -0.3877  0.1171  0.5048   \n",
       "1  799.58812  437.903860  282.945450  1.8511   6.31 -0.2928  0.0687  0.3615   \n",
       "2    0.00000   35.610036   35.610036  0.0000  16.28 -0.2845  0.0506  0.3351   \n",
       "3  285.48839   38.982300   34.298920  2.1089  14.18 -0.2670 -0.0406  0.2263   \n",
       "4   80.46225   19.906490   19.906330  0.0000  23.95 -0.3385  0.1041  0.4426   \n",
       "\n",
       "         r2      zpve          U0           U           H           G      CV  \\\n",
       "0   35.3641  0.044749  -40.478930  -40.476062  -40.475117  -40.498597   6.469   \n",
       "1   19.0002  0.021375  -76.404702  -76.401867  -76.400922  -76.422349   6.002   \n",
       "2   59.5248  0.026841  -77.308427  -77.305527  -77.304583  -77.327429   8.574   \n",
       "3   59.9891  0.026603 -114.483613 -114.480746 -114.479802 -114.505268   6.413   \n",
       "4  109.5031  0.074542  -79.764152  -79.760666  -79.759722  -79.787269  10.098   \n",
       "\n",
       "  Structure  \n",
       "0         C  \n",
       "1         O  \n",
       "2       C#C  \n",
       "3       C=O  \n",
       "4        CC  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"Train_Data.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = train_data['Structure']\n",
    "superset = ''.join(structure)\n",
    "encoders = list(set(superset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict(zip(encoders,np.arange(len(encoders))))\n",
    "max_length = 0 \n",
    "len_encoders = len(encoders)\n",
    "for struct in structure:\n",
    "    max_length = max(len(struct),max_length)\n",
    "max_size = len(train_data)\n",
    "representation = np.zeros((max_size,max_length,len(encoders)))\n",
    "for index in range(max_size):\n",
    "    struct = structure[index]\n",
    "    j = 0\n",
    "    for i in struct:\n",
    "        representation[index,j,features[i]]=1\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 2000/len(train_data)\n",
    "data_y = train_data['CV']\n",
    "scaler_y = MinMaxScaler()\n",
    "data_y = scaler_y.fit_transform(np.array(train_data['CV']).reshape(-1, 1))\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(representation,data_y,train_size=train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kamesh-k/anaconda3/envs/RDKit/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 2000 samples, validate on 54773 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 3.6514e-05\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0093 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 3.6514e-05\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0078 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 3.6514e-05\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 9s 5ms/sample - loss: 0.0065 - acc: 0.0000e+00 - val_loss: 0.0032 - val_acc: 3.6514e-05\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0060 - acc: 0.0000e+00 - val_loss: 0.0029 - val_acc: 3.6514e-05\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0053 - acc: 0.0000e+00 - val_loss: 0.0027 - val_acc: 3.6514e-05\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 3.6514e-05\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0047 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 3.6514e-05\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 3.6514e-05\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0026 - val_acc: 3.6514e-05\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0023 - val_acc: 3.6514e-05\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0021 - val_acc: 3.6514e-05\n",
      "Epoch 13/50\n",
      "1984/2000 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(max_length, (3, 2), activation='relu', input_shape=(max_length,len_encoders,1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 1), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(1,activation='linear'))\n",
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mean_squared_error',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "train_X = train_X.reshape(-1,max_length,len_encoders,1)\n",
    "test_X = test_X.reshape(-1,max_length,len_encoders,1)\n",
    "history = model.fit(\n",
    "  train_X,\n",
    "  train_Y,\n",
    "  epochs=50,\n",
    "  validation_data = (test_X,test_Y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7937395492958079"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 20, 10, 22)        154       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 5, 22)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 3, 64)          12736     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 1, 64)          12352     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 91,291\n",
      "Trainable params: 91,291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  11\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 20, 10, 22)        154       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 5, 22)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 3, 64)          12736     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 4, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 2, 1, 64)          12352     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 91,291\n",
      "Trainable params: 66,049\n",
      "Non-trainable params: 25,242\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model = model\n",
    "print(\"Number of layers in the base model: \", len(transfer_model.layers))\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "fine_tune_at = 6\n",
    "for layer in transfer_model.layers[:fine_tune_at]:\n",
    "  layer.trainable =  False\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 54773 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 3.6514e-05\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0015 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 3.6514e-05\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 3.6514e-05\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0014 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 3.6514e-05\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0013 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 3.6514e-05\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 3.6514e-05\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 3.6514e-05\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0012 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 3.6514e-05\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 3.6514e-05\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 3.6514e-05\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0010 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 3.6514e-05\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 3.6514e-05\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0011 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 9.8499e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 9.0392e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 9.4778e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 9.1357e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 3.6514e-05\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 8.9958e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 8.4077e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 8.6527e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 8.5473e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 8.2524e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 8.0342e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 7.2950e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 7.0924e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 3.6514e-05\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 7.4522e-04 - acc: 0.0000e+00 - val_loss: 9.9802e-04 - val_acc: 3.6514e-05\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 6.6056e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 6.8579e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 6.8475e-04 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 3.6514e-05\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 6.2441e-04 - acc: 0.0000e+00 - val_loss: 9.9697e-04 - val_acc: 3.6514e-05\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 5.9427e-04 - acc: 0.0000e+00 - val_loss: 9.8299e-04 - val_acc: 3.6514e-05\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 5.8357e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 6.1173e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 5.7126e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 5.8312e-04 - acc: 0.0000e+00 - val_loss: 9.8527e-04 - val_acc: 3.6514e-05\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 5.9627e-04 - acc: 0.0000e+00 - val_loss: 9.9574e-04 - val_acc: 3.6514e-05\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 5.0144e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 5.4057e-04 - acc: 0.0000e+00 - val_loss: 9.8793e-04 - val_acc: 3.6514e-05\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 4.9680e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 4.8333e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 4.5457e-04 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 3.6514e-05\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 4.7015e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 4.6754e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 4.4722e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 4.1614e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 4.4025e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 3.9605e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 4.4387e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 4.0783e-04 - acc: 0.0000e+00 - val_loss: 0.0010 - val_acc: 3.6514e-05\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 4.0138e-04 - acc: 0.0000e+00 - val_loss: 9.9955e-04 - val_acc: 3.6514e-05\n"
     ]
    }
   ],
   "source": [
    "transfer_model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mean_squared_error',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "train_size = 2000/len(train_data)\n",
    "data_y = train_data['gap']\n",
    "scaler_y = MinMaxScaler()\n",
    "data_y = scaler_y.fit_transform(np.array(train_data['gap']).reshape(-1, 1))\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(representation,data_y,train_size=train_size)\n",
    "\n",
    "train_X = train_X.reshape(-1,max_length,len_encoders,1)\n",
    "test_X = test_X.reshape(-1,max_length,len_encoders,1)\n",
    "history = model.fit(\n",
    "  train_X,\n",
    "  train_Y,\n",
    "  epochs=50,\n",
    "  validation_data = (test_X,test_Y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 54773 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0065 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 1.8257e-05\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0058 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 1.8257e-05\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0055 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 1.8257e-05\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0052 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0049 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 1.8257e-05\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0046 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 1.8257e-05\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 1.8257e-05\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0045 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0042 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0038 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0037 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0036 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 1.8257e-05\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0034 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0054 - val_acc: 1.8257e-05\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0033 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0031 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0032 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0029 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0030 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0027 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0028 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 9s 4ms/sample - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 1.8257e-05\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0026 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0024 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0025 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0023 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0022 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 1.8257e-05\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0055 - val_acc: 1.8257e-05\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0020 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 1.8257e-05\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0021 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 7s 3ms/sample - loss: 0.0019 - acc: 0.0000e+00 - val_loss: 0.0058 - val_acc: 1.8257e-05\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 1.8257e-05\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 1.8257e-05\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 7s 4ms/sample - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0057 - val_acc: 1.8257e-05\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 8s 4ms/sample - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0056 - val_acc: 1.8257e-05\n"
     ]
    }
   ],
   "source": [
    "model_alpha = models.Sequential()\n",
    "model_alpha.add(layers.Conv2D(max_length, (3, 2), activation='relu', input_shape=(max_length,len_encoders,1)))\n",
    "model_alpha.add(layers.MaxPooling2D((2, 2)))\n",
    "model_alpha.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_alpha.add(layers.MaxPooling2D((2, 2)))\n",
    "model_alpha.add(layers.Conv2D(64, (3, 1), activation='relu'))\n",
    "model_alpha.add(layers.Flatten())\n",
    "model_alpha.add(layers.Dense(256,activation='relu'))\n",
    "model_alpha.add(Dropout(0.2))\n",
    "model_alpha.add(layers.Dense(128,activation='relu'))\n",
    "model_alpha.add(Dropout(0.2))\n",
    "model_alpha.add(layers.Dense(1,activation='linear'))\n",
    "model_alpha.compile(\n",
    "  optimizer='adam',\n",
    "  loss='mean_squared_error',\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "train_size = 2000/len(train_data)\n",
    "data_y = train_data['gap']\n",
    "scaler_y = MinMaxScaler()\n",
    "data_y = scaler_y.fit_transform(np.array(train_data['gap']).reshape(-1, 1))\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(representation,data_y,train_size=train_size)\n",
    "\n",
    "train_X = train_X.reshape(-1,max_length,len_encoders,1)\n",
    "test_X = test_X.reshape(-1,max_length,len_encoders,1)\n",
    "history = model_alpha.fit(\n",
    "  train_X,\n",
    "  train_Y,\n",
    "  epochs=50,\n",
    "  validation_data = (test_X,test_Y)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35705409819234024"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(model.predict(test_X),test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RDKit",
   "language": "python",
   "name": "rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
